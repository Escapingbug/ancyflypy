{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dff747b165eafb83af0679e8b19a57ca014b9430e1e38e38cea6b3bbab1f5350"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ancy —— 小鹤音形\n",
    "\n",
    "## 目标\n",
    "\n",
    "1. 尽量利用现有词库——搜狗细胞词库\n",
    "2. 不考虑支持繁体\n",
    "3. 尽量减少内存消耗，从而可以使用更多的细胞词库\n",
    "4. 词组输入：通过首字形+末字形组合减少重复\n",
    "\n",
    "## 思路\n",
    "\n",
    "1. 获取规范汉字\n",
    "2. 获取汉字编码：拼音编码+小鹤形码\n",
    "3. 拼接编码（输入方案中，利用 Rime 的拼写运算将音形相拼）\n",
    "4. 构造词组+编码\n",
    "5. 输出方案"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "d\nd\nd\ndv\ndv\ndv\n"
     ]
    }
   ],
   "source": [
    "# 规范汉字已经位于 stage1/hanzi.txt\n",
    "# 单字数据库（小鹤音形）也已经位于 stage2/single_ch.db\n",
    "# 得到单字形码\n",
    "import sqlite3\n",
    "\n",
    "single_ch_db = sqlite3.connect(\"stage2/single_ch.db\")\n",
    "chars = {}\n",
    "cursor = single_ch_db.cursor()\n",
    "for ch, encodings in cursor.execute(\"select character, encodings from single_characters\"):\n",
    "    if ch in chars:\n",
    "        # 只需要关注形码，形码不存在多音的情况\n",
    "        continue\n",
    "    shape_encoding = ''\n",
    "    for encoding in encodings.split(' '):\n",
    "        # 智能情况下，没必要考虑 *（隐藏不用的形码）\n",
    "        encoding = encoding.replace('*', '')\n",
    "        # 仅形码\n",
    "        encoding = encoding[2:]\n",
    "        if len(shape_encoding) < len(encoding):\n",
    "            shape_encoding = encoding\n",
    "    \n",
    "    chars[ch] = [shape_encoding]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n秊\n\n\n\n\n\n\n\n\n\n﨧\n"
     ]
    }
   ],
   "source": [
    "# 读取字拼音，所有没有形码的都暂时不加形码\n",
    "# 目前似乎没有办法自动化拆字\n",
    "\n",
    "from pypinyin import pinyin, Style\n",
    "\n",
    "\n",
    "# 调整多音字频率（利用明月拼音）\n",
    "char_multi_freq = {} # ch -> {vocal -> freq_percent}\n",
    "with open('data/luna_pinyin.dict.yaml', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "    for line in content.splitlines():\n",
    "        if not '%' in line:\n",
    "            continue\n",
    "        ch, vocal, freq_percent = line.split('\\t')\n",
    "        if len(ch) > 1:\n",
    "            continue\n",
    "        if not ch in char_multi_freq:\n",
    "            char_multi_freq[ch] = {}\n",
    "        char_multi_freq[ch][vocal] = float(freq_percent.strip('%'))\n",
    "\n",
    "with open('data/pinyin.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "char_vocal = {}\n",
    "char_freq = {}\n",
    "for line in content.splitlines():\n",
    "    splits = line.split()\n",
    "    ch = splits[1]\n",
    "    freq = splits[2]\n",
    "    if len(splits) <= 4:\n",
    "        print(ch)\n",
    "        continue\n",
    "    vocals = splits[4].replace('1', '').replace('2', '').replace('3', '').replace('4', '').split('/')\n",
    "    char_vocal[ch] = [set(vocals)]\n",
    "    char_freq[ch] = float(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# 输出字码\n",
    "char_encodings = {}\n",
    "with open('data/out_char.txt', 'w', encoding='UTF-8') as f:\n",
    "    for ch, ch_pinyin in char_vocal.items():\n",
    "        shape_encoding = chars.get(ch)\n",
    "        if shape_encoding is None:\n",
    "            shape_encoding = ['']\n",
    "        encodings = []\n",
    "        vocal_encoding = ch_pinyin[0]\n",
    "        encodings = itertools.product(vocal_encoding, shape_encoding)\n",
    "        encodings = list(map(lambda x: ':'.join(x), encodings))\n",
    "        freq = char_freq[ch]\n",
    "\n",
    "        for encoding in encodings:\n",
    "            if ch in char_multi_freq:\n",
    "                freq_percent = char_multi_freq[ch].get(encoding.split(':')[0])\n",
    "                if freq_percent is None:\n",
    "                    freq_percent = 0.0\n",
    "                freq = freq * (freq_percent / 100.0)\n",
    "            f.write('{}\\t{}\\t{}\\n'.format(ch, encoding, int(freq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypinyin import pinyin, Style\n",
    "\n",
    "# 读取词\n",
    "with open('data/dict.txt.big.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "    phrases = list(map(lambda line: (line.split()[0], int(line.split()[1])), content.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'c' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-4f3b4ed39b00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/out_phrase.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_workable_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}\\t{}\\t{}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-152-4f3b4ed39b00>\u001b[0m in \u001b[0;36mgen_workable_phrases\u001b[1;34m(phrases)\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mshape_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_shape_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase_vocal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_encodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mworkable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-152-4f3b4ed39b00>\u001b[0m in \u001b[0;36mget_shape_encoding\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     11\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                     \u001b[0mc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'c' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def gen_workable_phrases(phrases):\n",
    "    workable = [] # (phrase, encoding, freq)\n",
    "    for phrase, freq in phrases:\n",
    "        vocal = pinyin(phrase, style=Style.NORMAL)\n",
    "        phrase_vocals = itertools.product(*vocal)\n",
    "        for phrase_vocal in phrase_vocals:\n",
    "            def get_shape_encoding(x):\n",
    "                shape = chars.get(x)\n",
    "                if shape is None:\n",
    "                    print(x, shape)\n",
    "                    return ''\n",
    "                else:\n",
    "                    return shape[0]\n",
    "            shape_encodings = list(map(get_shape_encoding, phrase))\n",
    "            out = list(map(lambda x: ':'.join(x), zip(phrase_vocal, shape_encodings)))\n",
    "            workable.append((phrase, out, freq))\n",
    "    return workable\n",
    "\n",
    "with open('data/out_phrase.txt', 'w', encoding='UTF-8') as f:\n",
    "    for phrase, out, freq in gen_workable_phrases(phrases):\n",
    "        f.write('{}\\t{}\\t{}\\n'.format(phrase, ' '.join(out), freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入细胞词库\n",
    "# 首先使用 https://github.com/studyzy/imewlconverter/releases/tag/v2.9.0 转换为 搜狗拼音 txt\n",
    "with open('data/sogou.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "    lines = content.splitlines()\n",
    "\n",
    "with open('data/out_sogou.txt', 'w', encoding='UTF-8') as f:\n",
    "    for line in lines:\n",
    "        vocal, char = line.split(' ')\n",
    "        vocal = vocal.split(\"'\")[1:]\n",
    "        combination = list(zip(char, vocal))\n",
    "        out_phrase = ''\n",
    "        out_encoding = ''\n",
    "        for ch, v in combination:\n",
    "            shape = chars.get(ch)\n",
    "            if shape is None:\n",
    "                shape = ''\n",
    "            else:\n",
    "                shape = shape[0]\n",
    "            out_phrase += ch\n",
    "            out_encoding += ' ' + v + ':' + shape\n",
    "        f.write('{}\\t{}\\n'.format(out_phrase, out_encoding.strip()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 全部合并\n",
    "header = r'''# Rime default settings\n",
    "\n",
    "# Rime schema: ancy_flypy_extend\n",
    "\n",
    "# Rime dictionary: ancy_flypy_extend\n",
    "\n",
    "---\n",
    "name: ancy_flypy_extend\n",
    "version: \"0.2\"\n",
    "sort: by_weight\n",
    "use_preset_vocabulary: false\n",
    "...\n",
    "'''\n",
    "with open('data/out_char.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "with open('data/out_phrase.txt', 'r', encoding='UTF-8') as f:\n",
    "    content += f.read()\n",
    "\n",
    "with open('data/out_sogou.txt', 'r', encoding='UTF-8') as f:\n",
    "    content += f.read()\n",
    "\n",
    "with open('data/ancy_flypy_extend.dict.yaml', 'w', encoding='UTF-8') as f:\n",
    "    f.write(header + content)\n"
   ]
  }
 ]
}