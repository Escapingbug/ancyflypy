{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dff747b165eafb83af0679e8b19a57ca014b9430e1e38e38cea6b3bbab1f5350"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ancy —— 小鹤音形\n",
    "\n",
    "## 目标\n",
    "\n",
    "1. 尽量利用现有词库——搜狗细胞词库\n",
    "2. 不考虑支持繁体\n",
    "3. 尽量减少内存消耗，从而可以使用更多的细胞词库\n",
    "4. 词组输入：通过首字形+末字形组合减少重复\n",
    "\n",
    "## 思路\n",
    "\n",
    "1. 获取规范汉字\n",
    "2. 获取汉字编码：拼音编码+小鹤形码\n",
    "3. 拼接编码（输入方案中，利用 Rime 的拼写运算将音形相拼）\n",
    "4. 构造词组+编码\n",
    "5. 输出方案"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 规范汉字已经位于 stage1/hanzi.txt\n",
    "# 单字数据库（小鹤音形）也已经位于 stage2/single_ch.db\n",
    "# 得到单字形码\n",
    "import sqlite3\n",
    "\n",
    "single_ch_db = sqlite3.connect(\"stage2/single_ch.db\")\n",
    "chars = {}\n",
    "cursor = single_ch_db.cursor()\n",
    "for ch, encodings in cursor.execute(\"select character, encodings from single_characters\"):\n",
    "    if ch in chars:\n",
    "        # 只需要关注形码，形码不存在多音的情况\n",
    "        continue\n",
    "    shape_encoding = ''\n",
    "    for encoding in encodings.split(' '):\n",
    "        # 智能情况下，没必要考虑 *（隐藏不用的形码）\n",
    "        encoding = encoding.replace('*', '')\n",
    "        # 仅形码\n",
    "        encoding = encoding[2:]\n",
    "        if len(shape_encoding) < len(encoding):\n",
    "            shape_encoding = encoding\n",
    "    \n",
    "    chars[ch] = [shape_encoding]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n秊\n\n\n\n\n\n\n\n\n\n﨧\n"
     ]
    }
   ],
   "source": [
    "# 读取字拼音，所有没有形码的都暂时不加形码\n",
    "# 目前似乎没有办法自动化拆字\n",
    "\n",
    "from pypinyin import pinyin, Style\n",
    "\n",
    "\n",
    "# 调整多音字频率（利用明月拼音）\n",
    "char_multi_freq = {} # ch -> {vocal -> freq_percent}\n",
    "with open('data/luna_pinyin.dict.yaml', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "    for line in content.splitlines():\n",
    "        if not '%' in line:\n",
    "            continue\n",
    "        ch, vocal, freq_percent = line.split('\\t')\n",
    "        if len(ch) > 1:\n",
    "            continue\n",
    "        if not ch in char_multi_freq:\n",
    "            char_multi_freq[ch] = {}\n",
    "        char_multi_freq[ch][vocal] = float(freq_percent.strip('%'))\n",
    "\n",
    "with open('data/pinyin.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "char_vocal = {}\n",
    "char_freq = {}\n",
    "for line in content.splitlines():\n",
    "    splits = line.split()\n",
    "    ch = splits[1]\n",
    "    freq = splits[2]\n",
    "    if len(splits) <= 4:\n",
    "        print(ch)\n",
    "        continue\n",
    "    vocals = splits[4].replace('1', '').replace('2', '').replace('3', '').replace('4', '').split('/')\n",
    "    char_vocal[ch] = [set(vocals)]\n",
    "    char_freq[ch] = float(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# 输出字码\n",
    "char_encodings = {}\n",
    "with open('data/out_char.txt', 'w', encoding='UTF-8') as f:\n",
    "    for ch, ch_pinyin in char_vocal.items():\n",
    "        shape_encoding = chars.get(ch)\n",
    "        if shape_encoding is None:\n",
    "            shape_encoding = ['']\n",
    "        encodings = []\n",
    "        vocal_encoding = ch_pinyin[0]\n",
    "        encodings = itertools.product(vocal_encoding, shape_encoding)\n",
    "        encodings = list(map(lambda x: ':'.join(x), encodings))\n",
    "        freq = char_freq[ch]\n",
    "\n",
    "        for encoding in encodings:\n",
    "            if ch in char_multi_freq:\n",
    "                freq_percent = char_multi_freq[ch].get(encoding.split(':')[0])\n",
    "                if freq_percent is None:\n",
    "                    freq_percent = 0.0\n",
    "                freq = freq * (freq_percent / 100.0)\n",
    "            f.write('{}\\t{}\\t{}\\n'.format(ch, encoding, int(freq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypinyin import pinyin, Style\n",
    "\n",
    "# 读取词\n",
    "with open('data/dict.txt.big.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "    phrases = list(map(lambda line: (line.split()[0], int(line.split()[1])), content.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_workable_phrases(phrases):\n",
    "    workable = [] # (phrase, encoding, freq)\n",
    "    for phrase, freq in phrases:\n",
    "        if len(phrase) == 1:\n",
    "            continue\n",
    "        vocal = pinyin(phrase, style=Style.NORMAL)\n",
    "        phrase_vocals = itertools.product(*vocal)\n",
    "        for phrase_vocal in phrase_vocals:\n",
    "            shape_encodings = []\n",
    "            skip = False\n",
    "            for p in phrase:\n",
    "                shape = chars.get(p)\n",
    "                if shape is None:\n",
    "                    skip = True\n",
    "                else:\n",
    "                    shape_encodings.append(shape[0])\n",
    "            if skip:\n",
    "                continue\n",
    "            out = list(map(lambda x: ':'.join(x), zip(phrase_vocal, shape_encodings)))\n",
    "            workable.append((phrase, out, freq))\n",
    "    return workable\n",
    "\n",
    "with open('data/out_phrase.txt', 'w', encoding='UTF-8') as f:\n",
    "    for phrase, out, freq in gen_workable_phrases(phrases):\n",
    "        f.write('{}\\t{}\\t{}\\n'.format(phrase, ' '.join(out), freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入细胞词库\n",
    "# 首先使用 https://github.com/studyzy/imewlconverter/releases/tag/v2.9.0 转换为 搜狗拼音 txt\n",
    "with open('data/sogou.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "    lines = content.splitlines()\n",
    "\n",
    "with open('data/out_sogou.txt', 'w', encoding='UTF-8') as f:\n",
    "    for line in lines:\n",
    "        vocal, char = line.split(' ')\n",
    "        vocal = vocal.split(\"'\")[1:]\n",
    "        combination = list(zip(char, vocal))\n",
    "        out_phrase = ''\n",
    "        out_encoding = ''\n",
    "        for ch, v in combination:\n",
    "            shape = chars.get(ch)\n",
    "            if shape is None:\n",
    "                shape = ''\n",
    "            else:\n",
    "                shape = shape[0]\n",
    "            out_phrase += ch\n",
    "            out_encoding += ' ' + v + ':' + shape\n",
    "        f.write('{}\\t{}\\n'.format(out_phrase, out_encoding.strip()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 全部合并\n",
    "header = r'''# Rime default settings\n",
    "\n",
    "# Rime schema: ancy_flypy_extend\n",
    "\n",
    "# Rime dictionary: ancy_flypy_extend\n",
    "\n",
    "---\n",
    "name: ancy_flypy_extend\n",
    "version: \"0.2\"\n",
    "sort: by_weight\n",
    "use_preset_vocabulary: false\n",
    "...\n",
    "'''\n",
    "\n",
    "singles = [\n",
    "    ('一', 'y'),\n",
    "    ('个', 'g'),\n",
    "    ('非', 'f'),\n",
    "    ('他', 't'),\n",
    "    ('不', 'b'),\n",
    "    ('可', 'k'),\n",
    "    ('的', 'd'),\n",
    "    ('小' ,'x'),\n",
    "    ('三', 's'),\n",
    "    ('才', 'c'),\n",
    "    ('出', 'i'),\n",
    "    ('去', 'q'),\n",
    "    ('哦', 'o'),\n",
    "    ('在', 'z'),\n",
    "    ('这', 'v'),\n",
    "    ('就', 'j'),\n",
    "    ('是', 'u'),\n",
    "    ('你', 'n'),\n",
    "    ('我', 'w'),\n",
    "    ('二', 'e'),\n",
    "    ('人', 'r'),\n",
    "    ('没', 'm'),\n",
    "    ('和', 'h'),\n",
    "    ('平', 'p'),\n",
    "    ('了', 'l'),\n",
    "    ('啊', 'a')\n",
    "]\n",
    "\n",
    "for ch, encoding in singles:\n",
    "    header += '{}\\t{}\\t10000000\\n'.format(ch, encoding)\n",
    "\n",
    "with open('data/out_char.txt', 'r', encoding='UTF-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "with open('data/out_phrase.txt', 'r', encoding='UTF-8') as f:\n",
    "    content += f.read()\n",
    "\n",
    "with open('data/out_sogou.txt', 'r', encoding='UTF-8') as f:\n",
    "    content += f.read()\n",
    "\n",
    "with open('data/ancy_flypy_extend.dict.yaml', 'w', encoding='UTF-8') as f:\n",
    "    f.write(header + content)\n"
   ]
  }
 ]
}